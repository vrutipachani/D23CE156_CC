{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyd6FtJ18pSo"
      },
      "outputs": [],
      "source": [
        "lass LaxicalAnalyzer:\n",
        "  def __init__(self):\n",
        "    self.keywords=['auto',\t'break',\t'case',\t'char', 'const',\t'continue',\t'default',\t'do', 'double',\t'else',\t'enum',\t'extern', 'float',\n",
        "                   'for',\t'goto',\t'if', 'int',\t'long',\t'register',\t'return', 'short',\t'signed',\t'sizeof',\t'static', 'struct',\t'switch',\n",
        "                   'typedef',\t'union', 'unsigned',\t'void',\t'volatile',\t'while']\n",
        "    self.punctuations=[';', ',', '(', ')', '{', '}', '[', ']', '#']\n",
        "    self.operators=['+', '-', '*', '/', '%', '=', '<', '>', '!', '&', '|', '^']\n",
        "    self.symbol_table = []\n",
        "\n",
        "  def is_keyword(self, word):\n",
        "    return word in self.keywords\n",
        "\n",
        "  def is_punctuation(self,char):\n",
        "    return char in self.punctuations\n",
        "\n",
        "  def is_operator(self,char):\n",
        "    return char in self.operators\n",
        "\n",
        "  def is_digit(self,char):\n",
        "    return '0'<= char <='9'\n",
        "\n",
        "  def is_identifier_start(self,char):\n",
        "    return char.isalpha() or char == '_'\n",
        "\n",
        "  def is_identifier_part(self,char):\n",
        "    return char.isalnum() or char == '_'\n",
        "\n",
        "  def remove_comments(self,code):\n",
        "    clean_code = \"\"\n",
        "    i = 0\n",
        "    while i < len(code):\n",
        "      if code[i:i+2] == '//':\n",
        "        while code[i] != '\\n' and i<len(code):\n",
        "          i = i+1\n",
        "\n",
        "      elif code[i:i+2] == '/*':\n",
        "        i = i+2\n",
        "        while code[i:i+2] != '*/' and i<len(code):\n",
        "          i = i + 1\n",
        "        i = i+2\n",
        "\n",
        "      else:\n",
        "        clean_code = clean_code + code[i]\n",
        "        i = i+1\n",
        "\n",
        "    return clean_code\n",
        "\n",
        "\n",
        "  def tokenize(self,code):\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while (i<len(code)):\n",
        "      ## Remove white space\n",
        "      if code[i].isspace():\n",
        "        i = i+1\n",
        "        continue\n",
        "      ## check whether the word is identifier or keyword?\n",
        "      if self.is_identifier_start(code[i]):\n",
        "        start = i\n",
        "        i = i+1\n",
        "        while i<len(code) and self.is_identifier_part(code[i]):\n",
        "          i=i+1\n",
        "        word = code[start:i]\n",
        "        if self.is_keyword(word):\n",
        "          tokens.append(('keyword',word))\n",
        "        else:\n",
        "          tokens.append(('identifier',word))\n",
        "          if word not in self.symbol_table:\n",
        "            self.symbol_table.append(word)\n",
        "        continue\n",
        "      ## check for the integer/digit (only intefers)\n",
        "      elif self.is_digit(code[i]) and not self.is_identifier_start(code[i+1]):\n",
        "        start = i\n",
        "        i = i+1\n",
        "        while i<len(code) and self.is_digit(code[i]) and not self.is_identifier_start(code[i+1]):\n",
        "          i = i+1\n",
        "        tokens.append(('constant',code[start:i]))\n",
        "        continue\n",
        "      ## check for the punctuation\n",
        "      elif self.is_punctuation(code[i]):\n",
        "        tokens.append(('punctuation',code[i]))\n",
        "        i = i+1\n",
        "        continue\n",
        "      ## check for operators\n",
        "      elif self.is_operator(code[i]):\n",
        "        start = i\n",
        "        i = i+1\n",
        "        while i<len(code) and self.is_operator(code[i]):\n",
        "          i = i+1\n",
        "        tokens.append(('operator',code[start:i]))\n",
        "        continue\n",
        "      ## check for string literals\n",
        "      elif code[i] == '\"':\n",
        "        start = i\n",
        "        i=i+1\n",
        "        while i<len(code) and code[i] != '\"':\n",
        "          i = i+1\n",
        "        if i<len(code):\n",
        "          tokens.append(('string literal',code[start:i+1])) # include closing quote\n",
        "          i = i+1\n",
        "        else:\n",
        "          tokens.append((\"error! Undeterminated string literal\"))\n",
        "        continue\n",
        "      ## check for Unrecognize charecter\n",
        "      else:\n",
        "        tokens.append((\"error! Unrecognize charecter\",code[i]))\n",
        "        i = i+1\n",
        "        continue\n",
        "    return tokens\n",
        "\n",
        "  def analyze(self,code):\n",
        "    clean_code = self.remove_comments(code)\n",
        "    tokens = self.tokenize(code)\n",
        "    return tokens,self.symbol_table"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Function\n",
        "def main():\n",
        "\n",
        "    c_program= \"\"\"\n",
        "    int main()\n",
        "    {\n",
        "      int a = 5 , 7H;\n",
        "      // assign value\n",
        "      char b = 'x';\n",
        "      /* return\n",
        "      value */\n",
        "      return a + b;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # c_program = \"\"\"\n",
        "    # /* salary calculation*/\n",
        "    # void main( )\n",
        "    # {\n",
        "    #   long int bs , da , hra , gs;\n",
        "    #   //take basic salary as input\n",
        "    #   scanf(\"%ld\",&bs);\n",
        "    #   //calculate allowances\n",
        "    #   da=bs*.40;\n",
        "    #   hra=bs*.20;\n",
        "    #   gs=bs+da+hra;\n",
        "    #   // display salary slip\n",
        "    #   printf(\"\\n\\nbs : %ld\",bs);\n",
        "    #   printf(\"\\nda : %ld\",da);\n",
        "    #   printf(\"\\nhra : %ld\",hra);\n",
        "    #   printf(\"\\ngs : %ld\",gs);\n",
        "    # }\n",
        "    # \"\"\"\n",
        "\n",
        "    # c_program = \"\"\"\n",
        "    # //function prototype\n",
        "    # void add ( int , int );\n",
        "    # void main( )\n",
        "    # {\n",
        "    #   int a , b;\n",
        "    #   a = 10;\n",
        "    #   b = 20;\n",
        "    #   // function call\n",
        "    #   add ( a , b );\n",
        "    # }\n",
        "    # void add ( int x , int y )\n",
        "    # {\n",
        "    #   return x + y;\n",
        "    # }\n",
        "    # \"\"\"\n",
        "\n",
        "    # c_program = \"\"\"\n",
        "    # // user defined data type\n",
        "    # struct student\n",
        "    # {\n",
        "    #   int id;\n",
        "    #   float cgpa;\n",
        "    # }\n",
        "    # void main( )\n",
        "    # {\n",
        "    #   student s;\n",
        "    #   s.id = 10;\n",
        "    #   s.cgpa = 8.7;\n",
        "    # }\n",
        "    # \"\"\"\n",
        "\n",
        "    lexer = LaxicalAnalyzer()\n",
        "\n",
        "    c_program = lexer.remove_comments(c_program)\n",
        "\n",
        "    tokens, symbol_table = lexer.analyze(c_program)\n",
        "\n",
        "    print(\"\\nTokens:\")\n",
        "    for token_type, value in tokens:\n",
        "        print(f\"{token_type}: {value}\")\n",
        "\n",
        "    print(\"\\nSymbol Table:\")\n",
        "    print(symbol_table)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXWT1phbKM9T",
        "outputId": "ae2d80b3-4180-4208-e3f0-2a59b11d2f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokens:\n",
            "keyword: int\n",
            "identifier: main\n",
            "punctuation: (\n",
            "punctuation: )\n",
            "punctuation: {\n",
            "keyword: int\n",
            "identifier: a\n",
            "operator: =\n",
            "constant: 5\n",
            "punctuation: ,\n",
            "error! Unrecognize charecter: 7\n",
            "identifier: H\n",
            "punctuation: ;\n",
            "keyword: char\n",
            "identifier: b\n",
            "operator: =\n",
            "error! Unrecognize charecter: '\n",
            "identifier: x\n",
            "error! Unrecognize charecter: '\n",
            "punctuation: ;\n",
            "keyword: return\n",
            "identifier: a\n",
            "operator: +\n",
            "identifier: b\n",
            "punctuation: ;\n",
            "punctuation: }\n",
            "\n",
            "Symbol Table:\n",
            "['main', 'a', 'H', 'b', 'x']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0f42tBPinm6w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
